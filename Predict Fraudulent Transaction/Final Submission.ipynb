{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dj/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "import random\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing, metrics, ensemble, neighbors, linear_model, tree, model_selection\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn import manifold, decomposition\n",
    "from sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_y=train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat((train.loc[:,'num_var_1':'cat_var_42'],\n",
    "                      test.loc[:,'num_var_1':'cat_var_42']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_to_drop=['cat_var_24', 'cat_var_25', 'cat_var_26', 'cat_var_27', 'cat_var_28', 'cat_var_29', 'cat_var_30', \n",
    "             'cat_var_31', 'cat_var_32', 'cat_var_33', 'cat_var_34', 'cat_var_35', 'cat_var_36', 'cat_var_37', \n",
    "             'cat_var_38', 'cat_var_39', 'cat_var_40', 'cat_var_41','cat_var_42', 'num_var_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data=all_data.drop(col_to_drop, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data['cat_var_1']=all_data['cat_var_1'].fillna('Nan')\n",
    "all_data['cat_var_3']=all_data['cat_var_3'].fillna('Nan')\n",
    "all_data['cat_var_6']=all_data['cat_var_6'].fillna('Nan')\n",
    "all_data['cat_var_8']=all_data['cat_var_8'].fillna('Nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder=all_data.groupby('cat_var_1').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_1_freq']=all_data.cat_var_1.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_2').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_2_freq']=all_data.cat_var_2.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_3').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_3_freq']=all_data.cat_var_3.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_6').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_6_freq']=all_data.cat_var_6.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_7').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_7_freq']=all_data.cat_var_7.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_8').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_8_freq']=all_data.cat_var_8.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_10').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_10_freq']=all_data.cat_var_10.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_13').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_13_freq']=all_data.cat_var_13.map(encoder)\n",
    "\n",
    "encoder=all_data.groupby('cat_var_14').size()\n",
    "encoder=encoder/len(all_data)\n",
    "all_data['cat_var_14_freq']=all_data.cat_var_14.map(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_var_1</th>\n",
       "      <th>num_var_2</th>\n",
       "      <th>num_var_4</th>\n",
       "      <th>num_var_5</th>\n",
       "      <th>num_var_6</th>\n",
       "      <th>num_var_7</th>\n",
       "      <th>cat_var_1</th>\n",
       "      <th>cat_var_2</th>\n",
       "      <th>cat_var_3</th>\n",
       "      <th>cat_var_4</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_var_23</th>\n",
       "      <th>cat_var_1_freq</th>\n",
       "      <th>cat_var_2_freq</th>\n",
       "      <th>cat_var_3_freq</th>\n",
       "      <th>cat_var_6_freq</th>\n",
       "      <th>cat_var_7_freq</th>\n",
       "      <th>cat_var_8_freq</th>\n",
       "      <th>cat_var_10_freq</th>\n",
       "      <th>cat_var_13_freq</th>\n",
       "      <th>cat_var_14_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.302632e-08</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>1.800000e-07</td>\n",
       "      <td>2.302632e-08</td>\n",
       "      <td>2.368421e-08</td>\n",
       "      <td>1.115205e-08</td>\n",
       "      <td>Nan</td>\n",
       "      <td>ce</td>\n",
       "      <td>db</td>\n",
       "      <td>ep</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>0.667156</td>\n",
       "      <td>0.023058</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.135110</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.965789e-06</td>\n",
       "      <td>0.157872</td>\n",
       "      <td>2.105000e-06</td>\n",
       "      <td>2.769737e-07</td>\n",
       "      <td>7.965789e-06</td>\n",
       "      <td>2.433058e-06</td>\n",
       "      <td>da</td>\n",
       "      <td>tn</td>\n",
       "      <td>zl</td>\n",
       "      <td>tn</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.295931</td>\n",
       "      <td>0.009840</td>\n",
       "      <td>0.289718</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.135110</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.299744</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.828947e-08</td>\n",
       "      <td>0.089140</td>\n",
       "      <td>3.550000e-07</td>\n",
       "      <td>4.671053e-08</td>\n",
       "      <td>1.052632e-07</td>\n",
       "      <td>4.276014e-07</td>\n",
       "      <td>gf</td>\n",
       "      <td>ce</td>\n",
       "      <td>gs</td>\n",
       "      <td>tn</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.379122</td>\n",
       "      <td>0.667156</td>\n",
       "      <td>0.004132</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.379122</td>\n",
       "      <td>0.092515</td>\n",
       "      <td>0.380945</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.894737e-08</td>\n",
       "      <td>0.227239</td>\n",
       "      <td>1.050000e-06</td>\n",
       "      <td>1.381579e-07</td>\n",
       "      <td>2.190789e-07</td>\n",
       "      <td>1.848054e-08</td>\n",
       "      <td>Nan</td>\n",
       "      <td>ce</td>\n",
       "      <td>fy</td>\n",
       "      <td>ep</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.039514</td>\n",
       "      <td>0.667156</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>0.029980</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.034106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.321053e-06</td>\n",
       "      <td>0.160410</td>\n",
       "      <td>2.105000e-06</td>\n",
       "      <td>2.769737e-07</td>\n",
       "      <td>3.340789e-06</td>\n",
       "      <td>2.152983e-06</td>\n",
       "      <td>da</td>\n",
       "      <td>tn</td>\n",
       "      <td>zn</td>\n",
       "      <td>tn</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290023</td>\n",
       "      <td>0.295931</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.289718</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.135110</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.299744</td>\n",
       "      <td>0.711649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_var_1  num_var_2     num_var_4     num_var_5     num_var_6  \\\n",
       "0  2.302632e-08   0.040182  1.800000e-07  2.302632e-08  2.368421e-08   \n",
       "1  7.965789e-06   0.157872  2.105000e-06  2.769737e-07  7.965789e-06   \n",
       "2  7.828947e-08   0.089140  3.550000e-07  4.671053e-08  1.052632e-07   \n",
       "3  7.894737e-08   0.227239  1.050000e-06  1.381579e-07  2.190789e-07   \n",
       "4  3.321053e-06   0.160410  2.105000e-06  2.769737e-07  3.340789e-06   \n",
       "\n",
       "      num_var_7 cat_var_1 cat_var_2 cat_var_3 cat_var_4       ...        \\\n",
       "0  1.115205e-08       Nan        ce        db        ep       ...         \n",
       "1  2.433058e-06        da        tn        zl        tn       ...         \n",
       "2  4.276014e-07        gf        ce        gs        tn       ...         \n",
       "3  1.848054e-08       Nan        ce        fy        ep       ...         \n",
       "4  2.152983e-06        da        tn        zn        tn       ...         \n",
       "\n",
       "  cat_var_23 cat_var_1_freq cat_var_2_freq cat_var_3_freq cat_var_6_freq  \\\n",
       "0          0       0.039514       0.667156       0.023058       0.016274   \n",
       "1          0       0.290023       0.295931       0.009840       0.289718   \n",
       "2          0       0.379122       0.667156       0.004132       0.378800   \n",
       "3          0       0.039514       0.667156       0.002698       0.005679   \n",
       "4          0       0.290023       0.295931       0.000298       0.289718   \n",
       "\n",
       "  cat_var_7_freq cat_var_8_freq cat_var_10_freq cat_var_13_freq  \\\n",
       "0       0.998761       0.135110        0.030682        0.025584   \n",
       "1       0.998761       0.135110        0.036715        0.299744   \n",
       "2       0.998761       0.379122        0.092515        0.380945   \n",
       "3       0.998761       0.019988        0.029980        0.016051   \n",
       "4       0.998761       0.135110        0.049561        0.299744   \n",
       "\n",
       "  cat_var_14_freq  \n",
       "0        0.711649  \n",
       "1        0.711649  \n",
       "2        0.711649  \n",
       "3        0.034106  \n",
       "4        0.711649  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encoder(data):\n",
    "    '''Map the categorical variables to numbers to work with scikit learn'''\n",
    "    for col in data.columns:\n",
    "        if data.dtypes[col] == \"O\":\n",
    "            le = preprocessing.LabelEncoder()\n",
    "            data[col]=le.fit_transform(data[col])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_data=encoder(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = all_data[:len(train)]\n",
    "test_X = all_data[len(train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_id=test['transaction_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_feature_map(features):\n",
    "    outfile = open('xgb.fmap', 'w')\n",
    "    for i, feat in enumerate(features):\n",
    "        outfile.write('{0}\\t{1}\\tq\\n'.format(i,feat))\n",
    "    outfile.close()\n",
    "\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, feature_names=None, seed_val=0, rounds=500, dep=10, eta=0.1):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary:logistic\"\n",
    "    params['eval_metric'] = 'auc'\n",
    "    params[\"eta\"] = eta\n",
    "    params[\"subsample\"] = 0.7\n",
    "    params[\"min_child_weight\"] = 1\n",
    "    params[\"colsample_bytree\"] = 0.7\n",
    "    params[\"max_depth\"] = dep\n",
    "\n",
    "    params[\"silent\"] = 1\n",
    "    params[\"seed\"] = seed_val\n",
    "    #params[\"max_delta_step\"] = 2\n",
    "    #params[\"gamma\"] = 0.5\n",
    "    num_rounds = rounds\n",
    "\n",
    "    plst = list(params.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    if feature_names is not None:\n",
    "        create_feature_map(feature_names)\n",
    "        model.dump_model('xgbmodel.txt', 'xgb.fmap', with_stats=True)\n",
    "        importance = model.get_fscore(fmap='xgb.fmap')\n",
    "        importance = sorted(importance.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        imp_df = pd.DataFrame(importance, columns=['feature','fscore'])\n",
    "        imp_df['fscore'] = imp_df['fscore'] / imp_df['fscore'].sum()\n",
    "        imp_df.to_csv(\"imp_feat.txt\", index=False)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit=model.best_ntree_limit)\n",
    "    pred_test_y2 = model.predict(xgb.DMatrix(test_X2), ntree_limit=model.best_ntree_limit)\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "        return pred_test_y, loss, pred_test_y2\n",
    "    else:\n",
    "        return pred_test_y, loss, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runLGB(train_X, train_y, test_X, test_y=None, test_X2=None, feature_names=None, seed_val=0, rounds=500, dep=10, eta=0.1):\n",
    "    params = {}\n",
    "    params[\"objective\"] = \"binary\"\n",
    "    params['metric'] = 'auc'\n",
    "    params[\"max_depth\"] = dep\n",
    "    params[\"min_data_in_leaf\"] = 64\n",
    "    params[\"learning_rate\"] = eta\n",
    "    params[\"bagging_fraction\"] = 0.7\n",
    "    params[\"feature_fraction\"] = 0.7\n",
    "    params[\"bagging_freq\"] = 5\n",
    "    params[\"bagging_seed\"] = seed_val\n",
    "    params[\"verbosity\"] = 0\n",
    "    #params[\"reg_alpha\"] = 20\n",
    "    #params[\"reg_lambda\"] = 20\n",
    "    num_rounds = rounds\n",
    "\n",
    "    plst = list(params.items())\n",
    "    lgtrain = lgb.Dataset(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        lgtest = lgb.Dataset(test_X, label=test_y)\n",
    "        model = lgb.train(params, lgtrain, num_rounds, valid_sets=[lgtest], early_stopping_rounds=100, verbose_eval=20)\n",
    "    else:\n",
    "        lgtest = lgb.DMatrix(test_X)\n",
    "        model = lgb.train(params, lgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(test_X, num_iteration=model.best_iteration)\n",
    "    pred_test_y2 = model.predict(test_X2, num_iteration=model.best_iteration)\n",
    "\n",
    "    loss = 0\n",
    "    if test_y is not None:\n",
    "        loss = metrics.roc_auc_score(test_y, pred_test_y)\n",
    "        print(loss)\n",
    "        return pred_test_y, loss, pred_test_y2\n",
    "    else:\n",
    "        return pred_test_y, loss, pred_test_y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "def runCatB(train_X, train_y, test_X, test_y=None, test_X2=None, depth=8):\n",
    "    model = CatBoostClassifier(\n",
    "                                iterations = 1000,\n",
    "                                learning_rate = 0.1,\n",
    "                                depth = depth,\n",
    "                                od_type='Iter',\n",
    "                                od_wait=100,\n",
    "                                rsm=0.7,\n",
    "                                l2_leaf_reg=3,\n",
    "                                eval_metric = 'AUC', \n",
    "                                verbose=True,\n",
    "                                random_seed=42)\n",
    "    \n",
    "    model.fit(train_X, train_y, eval_set=(test_X, test_y))#, plot=True)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]\n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth : \", depth)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def runET(train_X, train_y, test_X, test_y=None, test_X2=None, depth=20, leaf=10, feat=0.8):\n",
    "    model = ensemble.ExtraTreesClassifier(\n",
    "                                        n_estimators = 100,\n",
    "                                        criterion = 'gini',\n",
    "                                        max_depth = depth,\n",
    "                                        min_samples_split = 10,\n",
    "                                        min_samples_leaf = leaf,\n",
    "                                        warm_start = True,\n",
    "                                        max_features =  feat,\n",
    "                                        #min_impurity_split = 0.1,\n",
    "                                        n_jobs = -1,\n",
    "                                        verbose = 3,\n",
    "                                        random_state = 0)\n",
    "    model.fit(train_X, train_y)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]\n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth, leaf, feat : \", depth, leaf, feat)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "def runADA(train_X, train_y, test_X, test_y=None, test_X2=None, depth=6):\n",
    "    model = AdaBoostClassifier(DecisionTreeClassifier(max_depth=depth, max_features=0.7, min_samples_leaf=5),\n",
    "                               n_estimators = 300,\n",
    "                               learning_rate = 0.2,\n",
    "                               random_state=42)\n",
    "    \n",
    "    model.fit(train_X, train_y)#, eval_set=(test_X, test_y))#, plot=True)\n",
    "    train_preds = model.predict_proba(train_X)[:,1]\n",
    "    test_preds = model.predict_proba(test_X)[:,1]\n",
    "    test_preds2 = model.predict_proba(test_X2)[:,1]\n",
    "    test_loss = 0\n",
    "    if test_y is not None:\n",
    "        train_loss = metrics.roc_auc_score(train_y, train_preds)\n",
    "        test_loss = metrics.roc_auc_score(test_y, test_preds)\n",
    "        print(\"Depth : \", depth)\n",
    "        print(\"Train and Test loss : \", train_loss, test_loss)\n",
    "    return test_preds, test_loss, test_preds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.701043\ttest-auc:0.699736\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.758102\ttest-auc:0.73217\n",
      "[40]\ttrain-auc:0.791475\ttest-auc:0.732451\n",
      "[60]\ttrain-auc:0.820601\ttest-auc:0.730105\n",
      "[80]\ttrain-auc:0.840729\ttest-auc:0.730549\n",
      "[100]\ttrain-auc:0.858166\ttest-auc:0.730872\n",
      "[120]\ttrain-auc:0.871303\ttest-auc:0.73048\n",
      "Stopping. Best iteration:\n",
      "[25]\ttrain-auc:0.767073\ttest-auc:0.734038\n",
      "\n",
      "[0.73403839041269503]\n",
      "[0]\ttrain-auc:0.701608\ttest-auc:0.697055\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.76059\ttest-auc:0.727775\n",
      "[40]\ttrain-auc:0.793423\ttest-auc:0.730925\n",
      "[60]\ttrain-auc:0.816584\ttest-auc:0.730136\n",
      "[80]\ttrain-auc:0.84192\ttest-auc:0.730972\n",
      "[100]\ttrain-auc:0.863632\ttest-auc:0.730667\n",
      "[120]\ttrain-auc:0.876143\ttest-auc:0.731899\n",
      "[140]\ttrain-auc:0.889013\ttest-auc:0.732608\n",
      "[160]\ttrain-auc:0.898926\ttest-auc:0.732201\n",
      "[180]\ttrain-auc:0.907543\ttest-auc:0.73056\n",
      "[200]\ttrain-auc:0.91687\ttest-auc:0.730624\n",
      "[220]\ttrain-auc:0.922464\ttest-auc:0.730567\n",
      "[240]\ttrain-auc:0.928792\ttest-auc:0.729682\n",
      "Stopping. Best iteration:\n",
      "[149]\ttrain-auc:0.892529\ttest-auc:0.733\n",
      "\n",
      "[0.73403839041269503, 0.73299978891126238]\n",
      "[0]\ttrain-auc:0.702897\ttest-auc:0.701667\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.760808\ttest-auc:0.729271\n",
      "[40]\ttrain-auc:0.800191\ttest-auc:0.731933\n",
      "[60]\ttrain-auc:0.826319\ttest-auc:0.730767\n",
      "[80]\ttrain-auc:0.849721\ttest-auc:0.730014\n",
      "[100]\ttrain-auc:0.864537\ttest-auc:0.730258\n",
      "[120]\ttrain-auc:0.875882\ttest-auc:0.729584\n",
      "Stopping. Best iteration:\n",
      "[29]\ttrain-auc:0.777267\ttest-auc:0.732105\n",
      "\n",
      "[0.73403839041269503, 0.73299978891126238, 0.73210455853518352]\n",
      "[0]\ttrain-auc:0.72547\ttest-auc:0.719744\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.760591\ttest-auc:0.727866\n",
      "[40]\ttrain-auc:0.794972\ttest-auc:0.728259\n",
      "[60]\ttrain-auc:0.818311\ttest-auc:0.727573\n",
      "[80]\ttrain-auc:0.844443\ttest-auc:0.73046\n",
      "[100]\ttrain-auc:0.863839\ttest-auc:0.730689\n",
      "[120]\ttrain-auc:0.87692\ttest-auc:0.729915\n",
      "[140]\ttrain-auc:0.890171\ttest-auc:0.728702\n",
      "[160]\ttrain-auc:0.902322\ttest-auc:0.728587\n",
      "[180]\ttrain-auc:0.910141\ttest-auc:0.727561\n",
      "[200]\ttrain-auc:0.918965\ttest-auc:0.727259\n",
      "Stopping. Best iteration:\n",
      "[101]\ttrain-auc:0.865061\ttest-auc:0.731024\n",
      "\n",
      "[0.73403839041269503, 0.73299978891126238, 0.73210455853518352, 0.73102395220141769]\n",
      "[0]\ttrain-auc:0.72556\ttest-auc:0.721139\n",
      "Multiple eval metrics have been passed: 'test-auc' will be used for early stopping.\n",
      "\n",
      "Will train until test-auc hasn't improved in 100 rounds.\n",
      "[20]\ttrain-auc:0.757195\ttest-auc:0.728005\n",
      "[40]\ttrain-auc:0.794927\ttest-auc:0.728768\n",
      "[60]\ttrain-auc:0.817213\ttest-auc:0.728443\n",
      "[80]\ttrain-auc:0.844936\ttest-auc:0.728826\n",
      "[100]\ttrain-auc:0.861531\ttest-auc:0.72809\n",
      "[120]\ttrain-auc:0.877513\ttest-auc:0.728489\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-auc:0.77045\ttest-auc:0.73058\n",
      "\n",
      "[0.73403839041269503, 0.73299978891126238, 0.73210455853518352, 0.73102395220141769, 0.73058031001182044]\n",
      "0.729543084584\n"
     ]
    }
   ],
   "source": [
    "kf = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "cv_scores = []\n",
    "pred_test_full = 0\n",
    "pred_val_full = np.zeros(train_X.shape[0])\n",
    "for dev_index, val_index in kf.split(train_X, train_y):\n",
    "    dev_X, val_X = train_X.iloc[dev_index,:], train_X.iloc[val_index,:]\n",
    "    dev_y, val_y = train_y[dev_index], train_y[val_index]\n",
    "\n",
    "        \n",
    "    pred_val, loss, pred_test = runXGB(dev_X, dev_y, val_X, val_y, test_X, rounds=5000, feature_names=dev_X.columns.tolist())\n",
    "            \n",
    "    pred_val_full[val_index] = pred_val\n",
    "    pred_test_full = pred_test_full + pred_test\n",
    "    cv_scores.append(loss)\n",
    "    print(cv_scores)\n",
    "pred_test_full /= 5.\n",
    "print(metrics.roc_auc_score(train_y, pred_val_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame({\"transaction_id\":test_id})\n",
    "out_df[\"target\"] = pred_test_full\n",
    "out_df.to_csv(\"XGB.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['XGB_val_full']=pred_val_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_X['XGB_val_full']=train['XGB_val_full']\n",
    "train_X['LGM_val_full']=train['LGM_val_full']\n",
    "train_X['ADA_val_full']=train['ADA_val_full']\n",
    "train_X['CatB_val_full']=train['CatB_val_full']\n",
    "train_X['ET_val_full']=train['ET_val_full']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "a=pd.read_csv('pred_test_XGB_Final.csv')\n",
    "b=pd.read_csv('pred_test_LGM_Final.csv')\n",
    "c=pd.read_csv('pred_test_ADA_Final.csv')\n",
    "d=pd.read_csv('pred_test_CatB_Final.csv')\n",
    "e=pd.read_csv('pred_test_ET_Final.csv')\n",
    "\n",
    "test_X['XGB_val_full']=a['target']\n",
    "test_X['LGM_val_full']=b['target']\n",
    "test_X['ADA_val_full']=c['target']\n",
    "test_X['CatB_val_full']=d['target']\n",
    "test_X['ET_val_full']=e['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/dj/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_X.drop(['ADA_val_full'], 1, inplace=True)\n",
    "test_X.drop(['ADA_val_full'], 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runLGB(dev_X, dev_y, val_X, val_y, test_X, rounds=5000)\n",
    "runCatB(dev_X, dev_y, val_X, val_y, test_X)\n",
    "runET(dev_X, dev_y, val_X, val_y, test_X)\n",
    "runADA(dev_X, dev_y, val_X, val_y, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_var_1</th>\n",
       "      <th>num_var_2</th>\n",
       "      <th>num_var_4</th>\n",
       "      <th>num_var_5</th>\n",
       "      <th>num_var_6</th>\n",
       "      <th>num_var_7</th>\n",
       "      <th>cat_var_1</th>\n",
       "      <th>cat_var_2</th>\n",
       "      <th>cat_var_3</th>\n",
       "      <th>cat_var_4</th>\n",
       "      <th>...</th>\n",
       "      <th>cat_var_6_freq</th>\n",
       "      <th>cat_var_7_freq</th>\n",
       "      <th>cat_var_8_freq</th>\n",
       "      <th>cat_var_10_freq</th>\n",
       "      <th>cat_var_13_freq</th>\n",
       "      <th>cat_var_14_freq</th>\n",
       "      <th>XGB_val_full</th>\n",
       "      <th>LGM_val_full</th>\n",
       "      <th>CatB_val_full</th>\n",
       "      <th>ET_val_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.302632e-08</td>\n",
       "      <td>0.040182</td>\n",
       "      <td>1.800000e-07</td>\n",
       "      <td>2.302632e-08</td>\n",
       "      <td>2.368421e-08</td>\n",
       "      <td>1.115205e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016274</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.135110</td>\n",
       "      <td>0.030682</td>\n",
       "      <td>0.025584</td>\n",
       "      <td>0.711649</td>\n",
       "      <td>0.061212</td>\n",
       "      <td>0.055136</td>\n",
       "      <td>0.059754</td>\n",
       "      <td>0.035387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.965789e-06</td>\n",
       "      <td>0.157872</td>\n",
       "      <td>2.105000e-06</td>\n",
       "      <td>2.769737e-07</td>\n",
       "      <td>7.965789e-06</td>\n",
       "      <td>2.433058e-06</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>607</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289718</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.135110</td>\n",
       "      <td>0.036715</td>\n",
       "      <td>0.299744</td>\n",
       "      <td>0.711649</td>\n",
       "      <td>0.053016</td>\n",
       "      <td>0.075225</td>\n",
       "      <td>0.051236</td>\n",
       "      <td>0.053073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.828947e-08</td>\n",
       "      <td>0.089140</td>\n",
       "      <td>3.550000e-07</td>\n",
       "      <td>4.671053e-08</td>\n",
       "      <td>1.052632e-07</td>\n",
       "      <td>4.276014e-07</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>158</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.379122</td>\n",
       "      <td>0.092515</td>\n",
       "      <td>0.380945</td>\n",
       "      <td>0.711649</td>\n",
       "      <td>0.066105</td>\n",
       "      <td>0.068473</td>\n",
       "      <td>0.064990</td>\n",
       "      <td>0.044393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.894737e-08</td>\n",
       "      <td>0.227239</td>\n",
       "      <td>1.050000e-06</td>\n",
       "      <td>1.381579e-07</td>\n",
       "      <td>2.190789e-07</td>\n",
       "      <td>1.848054e-08</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.019988</td>\n",
       "      <td>0.029980</td>\n",
       "      <td>0.016051</td>\n",
       "      <td>0.034106</td>\n",
       "      <td>0.051330</td>\n",
       "      <td>0.058330</td>\n",
       "      <td>0.055494</td>\n",
       "      <td>0.054163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.321053e-06</td>\n",
       "      <td>0.160410</td>\n",
       "      <td>2.105000e-06</td>\n",
       "      <td>2.769737e-07</td>\n",
       "      <td>3.340789e-06</td>\n",
       "      <td>2.152983e-06</td>\n",
       "      <td>66</td>\n",
       "      <td>50</td>\n",
       "      <td>609</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.289718</td>\n",
       "      <td>0.998761</td>\n",
       "      <td>0.135110</td>\n",
       "      <td>0.049561</td>\n",
       "      <td>0.299744</td>\n",
       "      <td>0.711649</td>\n",
       "      <td>0.061850</td>\n",
       "      <td>0.071204</td>\n",
       "      <td>0.056037</td>\n",
       "      <td>0.072610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      num_var_1  num_var_2     num_var_4     num_var_5     num_var_6  \\\n",
       "0  2.302632e-08   0.040182  1.800000e-07  2.302632e-08  2.368421e-08   \n",
       "1  7.965789e-06   0.157872  2.105000e-06  2.769737e-07  7.965789e-06   \n",
       "2  7.828947e-08   0.089140  3.550000e-07  4.671053e-08  1.052632e-07   \n",
       "3  7.894737e-08   0.227239  1.050000e-06  1.381579e-07  2.190789e-07   \n",
       "4  3.321053e-06   0.160410  2.105000e-06  2.769737e-07  3.340789e-06   \n",
       "\n",
       "      num_var_7  cat_var_1  cat_var_2  cat_var_3  cat_var_4     ...       \\\n",
       "0  1.115205e-08          0          3         75          0     ...        \n",
       "1  2.433058e-06         66         50        607          1     ...        \n",
       "2  4.276014e-07        128          3        158          1     ...        \n",
       "3  1.848054e-08          0          3        140          0     ...        \n",
       "4  2.152983e-06         66         50        609          1     ...        \n",
       "\n",
       "   cat_var_6_freq  cat_var_7_freq  cat_var_8_freq  cat_var_10_freq  \\\n",
       "0        0.016274        0.998761        0.135110         0.030682   \n",
       "1        0.289718        0.998761        0.135110         0.036715   \n",
       "2        0.378800        0.998761        0.379122         0.092515   \n",
       "3        0.005679        0.998761        0.019988         0.029980   \n",
       "4        0.289718        0.998761        0.135110         0.049561   \n",
       "\n",
       "   cat_var_13_freq  cat_var_14_freq  XGB_val_full  LGM_val_full  \\\n",
       "0         0.025584         0.711649      0.061212      0.055136   \n",
       "1         0.299744         0.711649      0.053016      0.075225   \n",
       "2         0.380945         0.711649      0.066105      0.068473   \n",
       "3         0.016051         0.034106      0.051330      0.058330   \n",
       "4         0.299744         0.711649      0.061850      0.071204   \n",
       "\n",
       "   CatB_val_full  ET_val_full  \n",
       "0       0.059754     0.035387  \n",
       "1       0.051236     0.053073  \n",
       "2       0.064990     0.044393  \n",
       "3       0.055494     0.054163  \n",
       "4       0.056037     0.072610  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X=train_X.loc[:,'num_var_1':'cat_var_14_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_X=test_X.loc[:,'num_var_1':'cat_var_14_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
